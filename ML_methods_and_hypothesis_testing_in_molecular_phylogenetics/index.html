<!doctype html>
<html lang="en">

<head>
	<meta charset="utf-8">

	<title>Maximum Likelihood Methods and Hypothesis Testing</title>
	<meta name="author" content="Filip Bielejec">

	<meta name="apple-mobile-web-app-capable" content="yes" />
	<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />
	<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

	<link rel="stylesheet" href="../reveal/css/reveal.min.css">
	<link rel="stylesheet" href="../reveal/css/bootstrap.min.css">
	<link rel="stylesheet" href="../reveal/css/theme/filip.css" id="theme">
	<link rel="stylesheet" href="../reveal/css/font-awesome/css/font-awesome.min.css">
	<link rel="stylesheet" href="../reveal/lib/css/zenburn.css">

</head>

<body>

	<div style="position: absolute; top:10px; left:10px; z-index:100;">
		<a href="../index.html">
			<i class="fa fa-times-circle" style="color: #bbb;"></i>
		</a>
	</div>

	<div class="reveal">
		<div class="slides">

			<section data-background="#cce8cf" data-background-transition="none">
				<h2>Maximum Likelihood Methods and Hypothesis Testing</h2>
				<h3>in Molecular Phylogenetics</h3>
				<br>
				<p><a href="https://twitter.com/fbielejec">Filip Bielejec</a> / <a href="https://github.com/fbielejec">@fbielejec</a></p>
				<p><a href="http://rega.kuleuven.be/cev/ecv">ECV - Evolutionary and Computational Virology</a></p>
				<p><a href="https://www.kuleuven.be/english">KU Leuven</a></p>
			</section>

			<section data-background="images/overImg.png" data-background-transition="none" data-transition="convex">
				<h3>About me</h3>
				<br>
				<ul>
					<li>Studied Applied Mathematics at <a href="http://www.p.lodz.pl/en">Lodz University of Technology</a></li>
					<li>Postdoctoral researcher at the lab of <a href="http://rega.kuleuven.be/cev/ecv/lab-members/PhilippeLemey.html">Philippe Lemey</a></li>
					<li>Enthusiast of data visualization, parallel and distributed computing</li>
					<li>Author of <a href="http://rega.kuleuven.be/cev/ecv/software/pibuss">Ï€BUSS</a>,
						<a href="https://rega.kuleuven.be/cev/ecv/tutorials/tree-imp-tutorial">Imp</a> and
						<a href="http://rega.kuleuven.be/cev/ecv/software/SpreaD3">SpreaD3</a> </li>
				</ul>
			</section>

			<section data-background="#cce8cf" data-background-transition="none" data-transition="slide">
				<h3>Cuban Bioinformatics Workshop on</h3>
				<h4>Virus Evolution and Molecular Epidemiology</h4>
				<br>
				<span> Slides can be downloaded from:</span>
				<br>
				<a href="https://github.com/fbielejec/veme2016"> https://github.com/fbielejec/veme2016</a>
				<br>
					<br>
				<span> Slides are also availiable online:</span>
				<br>
				<a href="https://fbielejec.github.io/veme2016"> http://fbielejec.github.io/veme2016</a>
			</section>


		<section data-background="#cce8cf" data-background-transition="none" data-transition="none">
				<h2>Phylogenetics</h2>
			</section>

			<section data-background="none" data-background-transition="none">
			<h2>Molecular evolution</h2>
			<p>The process of random change in the sequence composition of cellular molecules, such as DNA, over time.</p>
			</section>

			<section data-background="images/overImg.png" data-background-transition="none" data-transition="none">
				<h3>Observed data</h3>
				<img class="stretch" src="images/observed.png">
			</section>

<!-- tree  -->
<section data-background="images/overImg.png" data-background-transition="none" data-transition="none">
		 <!-- directed acyclic graph -->
	 <!-- tree is a hypothesis based on observed data -->
	<h3>Phylogenetic tree</h3>
	<img class="stretch" src="images/tree1.png">
</section>



<section data-background="images/overImg.png" data-background-transition="none" data-transition="none">
	<!-- series of mutation events leads to the observed data -->
	<h3>Mutation events generate observed data</h3>
	<img class="stretch" src="images/tree2.png">
</section>

<section data-background="#cce8cf" data-background-transition="none">
	<h2>Evolution as a stochastic process</h2>
</section>

<section data-background="none" data-background-transition="none" data-transition="none">
<img src="images/t0.png">
</section>


<section data-background="none" data-background-transition="none" data-transition="none">
<img src="images/t2.png">
</section>


<section data-background="none" data-background-transition="none" data-transition="none">
<img src="images/t3.png">
</section>


<section data-background="none" data-background-transition="none" data-transition="none">
<img src="images/t4.png">
</section>


<section data-background="images/overImg.png" data-background-transition="none" data-transition="none">
	<h3>Substitution models</h3>
	<div class="row">
			<div class="col-sm-6" style="">
				<br>
				<br>
				<!-- <br> -->
<font size=5>
			<!-- <a class="stretch"><img src="images/substitution.png"></a> -->
			<!-- $\mathbf{P}(t)=$ -->
			<!-- <br> -->
			$\left[\begin{array}{cccc} A\rightarrow A & {\color{red}A\color{red}\rightarrow \color{red}C} & {\color{green}A\color{green}\rightarrow
				\color{green}G} & {\color{blue}A\color{blue}\rightarrow \color{blue}T}\\ {\color{red}C\color{red}\rightarrow \color{red}A} & C\rightarrow C & {\color{cyan}C\color{cyan}\rightarrow \color{cyan}G} & {\color{magenta}C\color{magenta}\rightarrow \color{magenta}T}\\
				{\color{green}G\color{green}\rightarrow \color{green}A} & {\color{cyan}G\color{cyan}\rightarrow \color{cyan}C} & G\rightarrow G & {\color{yellow}G\color{yellow}\rightarrow \color{yellow}T}\\ {\color{blue}T\color{blue}\rightarrow \color{blue}A} &
				{\color{magenta}T\color{magenta}\rightarrow \color{magenta}C} & {\color{yellow}T\color{yellow}\rightarrow \color{yellow}G} & T\rightarrow T \end{array}\right]$
</font>

		</div>
		<div class="col-sm-6">
			<font size=5>
			<ul>
				<li>Continuous Time Markov Chain (CTMC) models describe character substitutions at particular site in the alignment.</li>
			</ul>
			<ul class="fragment">
				<li>Characterized by $K \times K$ rate matrix $\mathbf{Q}$.</li>
				<li>
					Finite-time transition probability matrix $\mathbf{P}$ is obtained via matrix exponentiation: $P(t)=e^{Qt}=\underset{n=0}{\overset{\infty}{\sum}}Q^{n}\frac{t^{n}}{n!}$.</li>
				<li>
					Single entry is a conditional probability:
					<!-- <font size=5> -->
				${\color{red}A\color{red}\rightarrow \color{red}C}:\quad \forall u\geq 0 \quad p_{AC}(t)=P\left\{ X\left(t+u\right)=C\mid X(u)=A\right\}$.
<!-- </font> -->
				</li>
			</ul>
			</font>
		</div>
	</div>
</section>

<section data-background="images/overImg.png" data-background-transition="none">
	<h3>Continuous time Markov chain models</h3>
	<div class="row">

		<div class="row">
			<div class="col-sm-6">
				<a class="stretch"><img src="images/ctmc.png"></a>
			</div>
			<div class="col-sm-6">
				<h4>CTMC is a stochastic process of sequential transitions from one state to another, within an allowed set of states
		$X(t_{0})\rightarrow X(t_{1})\rightarrow\ldots\rightarrow X(t_{n})\rightarrow\ldots$
	</h4>
			</div>
		</div>

		<div class="col-sm-12">
			<h4><span>Simplifying assumptions:</span></h4>
			<ul>

				<li>Markov property:
					<font size=5>$P\left\{ X(t_{n+1}) = i_{n+1}\mid X(t_{n})=i_{n},\ldots, X(t_{0})=i_{0}\right\} = P\left\{ X(t_{n+1}) = i_{n+1}\mid X(t_{n})=i_{n}\right\}$</font>
				</li>

				<li class="fragment">
					Homogeneity: $\forall i,j\in \mathcal{E} \quad p_{ij}\left(t\right) = p_{ij}\left(0,t\right) = p_{ij}\left(u,t+u\right)$
				</li>

				<li class="fragment">
					Stationarity: $\forall j\in\mathcal{E} \quad \exists\pi_{j}>0 \quad \forall i\in\mathcal{E}\quad\underset{t\rightarrow\infty}{lim}p_{ij}(t)=\pi_{j}$
				</li>

				<li class="fragment">
					Time-reversibility: $\forall i,j\in \mathcal{E} \quad \pi_{i}p_{ij}(t)=\pi_{j}p_{ji}(t)$
				</li>

			</ul>
		</div>

	</div>
</section>

<section data-background="none" data-background-transition="none" data-transition="slide">
	<h3>Example: JC69 substitution model</h3>

	<ul>
		<li> The simplest model of nucleotide substitution
			<a href="http://garfield.library.upenn.edu/classics1990/A1990CZ67100002.pdf">[Jukes and Cantor, 1969]</a>
		</li>
		<li> Transition probabilities are given by: $p_{ij}\left(t\right)=\begin{cases}
			\frac{1}{4}+\frac{3}{4}e^{-4\theta t} & \text{if }i=j\\ \frac{1}{4}-\frac{1}{4}e^{-4 \theta t} & \text{otherwise}
			\end{cases}$
		</li>
	</ul>
</section>

<section data-background="none" data-background-transition="none" data-transition="slide">
	<h3>Example: JC69 substitution model</h3>

	<p>
		<!-- Transition probabilities are given by:  -->
		$p_{ij}\left(t\right)=\begin{cases}
		\frac{1}{4}+\frac{3}{4}e^{-4\theta t} & \text{if }i=j\\ \frac{1}{4}-\frac{1}{4}e^{-4 \theta t} & \text{otherwise}
		\end{cases}$
	</p>

	<ul>
		<li> Let's assume the state is $G$ now. </li>
		<li> What is the probability the state will change to $T$ in $0.01$ units of time? Or 0.05? or 0.1? </li>
				<li> What happens if we change the initial state distribution? </li>
				<li class="fragment">	<font color="#df8f09">Let's see!</font></li>
	</ul>
	<br>
	<!-- <ul class="fragment">
		<li>
			Because of the homogeneity assumption it is not neccessary to run the chain sequentially through all iterations to predict a state in the future.
		</li>
		<li> We can predict the n-th iteration by raising the transition matrix $P$ to the n-th power and multiplying the result by the distribution of the initial state $\mathbf{\Pi}^{0}$:
			<br> $P\left\{ X\left(t_{n}\right)\right\} =\mathbf{\Pi}^{0}\times P^{n}$
		</li>
	</ul> -->
</section>


<!-- https://theclevermachine.wordpress.com/tag/markov-chain/ -->
<section data-background="images/overImg.png" data-background-transition="none">
	<h4><span>Example: JC69 substitution model</span></h4>
	<div class="row">
		<div class="col-md-12">
			<a class="stretch"><img style="max-width:50%; max-height:50%;" src="images/jc69.png"></a>
		</div>
	</div>
	<div class="row">
		<div class="col-md-12">
			<ul>
				<li> Here we see that at time $0.025$ the probability of $T$ is $\approx21\%$ </li>
				<li> After approx time $0.05$ the chain reaches its stationary distribution: </li>
				<li> $\mathbf{\Pi}=\left\{ \pi_{T}=0.25,\pi_{C}=0.25,\pi_{A}=0.25,\pi_{G}=0.25\right\}$ </li>
				<!-- <li> What happens if we change the initial state distribution? <font color="#df8f09">See the R script.</font></li> -->
			</ul>
		</div>
	</div>
</section>


<!-- <section data-background="images/overImg.png" data-background-transition="none" data-transition="none">
	<h3>Fabricating evolution</h3>
	<img class="stretch" src="images/simulating.png">
</section> -->

<section data-background="#cce8cf" data-background-transition="none" data-transition="slide">
	<h3>Maximum Likelihood (ML) approach</h3>
</section>

<!-- likelihood concept-->
<section data-background="images/overImg.png" data-background-transition="none" data-transition="none">
	<h3>Maximum likelihood inference</h3>
	<br>
			<p>
				<!-- theta represents some hypothesis -->
				<!-- if we considered the data fixed and parameter to be the variable -->
				Some data $D$ was generated by a model with a parameter $\theta$.
        The conditional probability of observing the data $\mathrm{Pr}(D \, | \, \theta)$, considered as a function of $\theta$
is called the likelihood function and denoted $\mathrm{L}(\theta \, | \, D)$.
</p>

<p class="fragment">
	To maximize the likelihood means to find a best parameter $\hat{\theta}$ which maximizes $\mathrm{L}(\theta \, | \, D)$.
	Such a parameter is then called the Maximum Likelihood Estimate (MLE).
</p>
</section>

<section data-background="none" data-background-transition="none" data-transition="slide">
	<h3>Maximum Likelihood Estimate</h3>
	<p>
		Likelihood is a function of parameter $\theta$:
		<br> $\mathrm{Pr}(D \, | \, \theta)=\mathrm{L}(\theta \, | \, D)$
	</p>
	<p class="fragment">
		To maximize the likelihood means to find a best parameter $\hat{\theta}$ which maximizes $\mathrm{L}(\theta \, | \, D)$. Such a parameter is then called the Maximum Likelihood Estimate (MLE).
	</p>
</section>



<!-- coin tosses -->
<section data-background="none" data-background-transition="none" data-transition="slide">
	<h3>Example: Coin tosses</h3>
	<p>
		Let us consider a coin with head and tail, which is flipped $10$ times, and lands on it's head $8$ times:
		<br> $H,H,H,T,H,H,H,H,H,T,H$
	</p>
	<p class="fragment">
		How to model the probability of such an outcome?
	</p>
	<ul class="fragment">
		<li> Data: $D=\left(k=8,n=10\right)$.</li>
		<li> Parameter: probability $\theta$ of landing a head.</li>
		<li class="fragment">
			Likelihood: given by the <a href="https://en.wikipedia.org/wiki/Binomial_distribution">Binomial distribution</a>: $$\mathrm{L}(\theta \, | \, k,n) = \left(\begin{array}{c} \begin{array}{c} n\\ k \end{array}\end{array}\right) \, \theta^k \, (1-\theta)^{n-k}.$$
			</li>
	</ul>
</section>


<section data-background="none" data-background-transition="none" data-transition="none">
	<h3>Example: Coin tosses</h3>
	<br>
	<img class="stretch" src="images/likelihood1.png">
	<p>
		<!-- analytically by taking the derivative, setting it equal to 0, solving for parameter -->
		Curve presents the likelihood function for the coin tosses example: $\mathrm{L}(\theta \, | \, k=8,n=10)$.
		Would you say the coin is fair?
			</p>
		<br>
			<p>
		<font color="#df8f09">To the R script!</font>
		<!-- <br> The MLE: $\hat{\theta}=\frac{8}{10}=0.8$ -->
	</p>
</section>


<section data-background="images/overImg.png" data-background-transition="none" data-transition="none">
	<h3>Maximum likelihood inference</h3>
	<br>
	<img class="stretch" src="images/likelihood1.png">
			<p>
				The likelihood curve
</p>
<!-- who know what will it be? -->
<p class="fragment">
	The MLE?
</p>
</section>

<section data-background="images/overImg.png" data-background-transition="none" data-transition="none">
	<h3>Maximum likelihood inference</h3>
	<br>
	<img class="stretch" src="images/likelihood2.png">
			<p>
				MLE maximizes likelihood function.
				<!-- analytically by taking the derivative, setting it equal to 0, solving for parameter -->
				<!-- ${\displaystyle \log L(\theta\,|\, k,n)=\log\binom{n}{k}+x\log(\theta)+(n-k)\log(1-\theta)}$
				${\displaystyle \frac{\partial\log L(\theta\,|\,8,10)}{\partial\theta}=\frac{8}{\theta}-\frac{10-8}{1-\theta}}=0\;\Longleftrightarrow\;\theta=0.8$ -->
</p>
</section>

<section data-background="#cce8cf" data-background-transition="none" data-transition="slide">
	<h3>Maximum Likelihood in phylogenetics</h3>
</section>

<section data-background="none" data-background-transition="none" data-transition="slide">
	<h3>Maximum Likelihood in phylogenetics</h3>
	<p>In phylogenetic analysis, the parameter $\theta$ is <font color="#df8f09">multidimensional</font> and comprises:</p>
	<ul>
		<li>Parameters of the evolutionary model, possibly multiple.</li>
				<li>Tree topology.</li>
				<li>Branch lengths.</li>
	</ul>
	<br>
	<br>
	<p class="fragment">
		This makes ML a <font color="#df8f09">high dimensional optimization problem</font> that usually cannot be solved in one
		go and instead a stepwise procedure is involved.
		<!-- the model parameters are often determined separately from the tree. -->
	</p>
</section>


<!-- Likelihood calculation on tree -->
<section data-background="images/overImg.png" data-background-transition="none" data-transition="none">
	<h3>Likelihood calculation on a fixed tree</h3>
	<div class="row">
		<div class="col-sm-6">
			<a class="stretch"><img src="images/pruning.png"></a>
		</div>
		<div class="col-sm-6">
<font size=5>
			<p>
<b>Assumptions:</b> After divergence characters evolve independently, sites evolve independently.
			</p>

			<p class="fragment">
<b>Inside brackets:</b> probability of the data $TGAA$ observed at the tips and $x_{0}x_{1}x_{2}$ for the internal nodes.
<br>
<b>Outside brackets:</b> sum over all possible path combinations in the state space $\mathcal{E}$.
			</p>
</font>
		</div>
	</div>
<p>
	<font size=5.5>
$\underset{x_{0}\in\varepsilon}{\sum}\underset{x_{1}\in\varepsilon}{\sum}\underset{x_{2}\in\varepsilon}{\sum}[\pi_{x_{0}}\cdot p_{x_{0}T}(t_{0})\cdot p_{x_{0}x_{1}}(t_{1})\cdot p_{x_{1}x_{2}}(t_{2})\cdot p_{x_{1}A}(t_{3})\cdot p_{x_{2}G}(t_{5})\cdot p_{x_{2}A}(t_{4})]$
</font>
</p>
</section>

<section data-background="images/overImg.png" data-background-transition="none" data-transition="none">
	<h3>Likelihood calculation on a tree</h3>
	<div class="row">
		<div class="col-sm-6">
			<a class="stretch"><img src="images/pruning.png"></a>
		</div>
		<div class="col-sm-6">

			<p>
Ancestral reconstruction: Finding the most probable path between the unobserved conditional on the observed characters.
			</p>

				<p class="fragment">
This means maximizing the likelihood of the data: $P(TGAA | x_0,x_1,x_2)$.
<!-- $L({x_0,x_1,x_2)} | TGAA)$.  -->
			</p>

<!-- you would have to enumerate all and find the one that maximizes the probability -->
			<p class="fragment">
Computationaly intensive! Proceeds at $\mathcal{O}\left(K^{n-1}\right)$, where $K$ is the size of state space $\mathcal{E}$, $n$ is the number of internal nodes.
		</p>

		</div>
	</div>
</section>


<!-- tree pruning -->
<section data-background="images/overImg.png" data-background-transition="none" data-transition="none">
	<h3>Likelihood calculation on a tree</h3>
	<div class="row">
		<div class="col-sm-6">
			<a class="stretch"><img src="images/pruning2.png"></a>
		</div>
		<div class="col-sm-6">
<font size=5>
			<p>
				Tree pruning <a>[Felsenstein 1981]</a>: recursive algorithm for calculating likelihood of a (observed) sequence on a tree.
			</p>
<br>
				<p class="fragment">
Partial likelihood $L_{i}(x_{i})$ of observing data at the descendants of node $i$ given state $x_{i}$ at node $i$ expressed in terms of partial likelihoods at nodes $j$ and $k$.
			</p>
<br>
<!-- from polynomial to quadratic -->
			<p class="fragment">
				Proceeds at $\mathcal{O}\left(K^{2} \times n \right)$.
		</p>
</font>
		</div>
	</div>
<p>
$L_{i}(x_{i})=\left[\underset{x_{j}\in \varepsilon}{\sum}p_{x_{i}x_{j}}(t_{j})L_{j}(x_{j})\right]\times\left[\underset{x_{k}\in \varepsilon}{\sum}p_{x_{i}x_{k}}(t_{k})L_{k}(x_{k})\right]$
	</p>
</section>

<!-- searching tree space -->
<section data-background="#cce8cf" data-background-transition="none" data-transition="none">
	<!-- by tree we understand topology and branch lengths -->
	<h3>What if the tree is not known?</h3>
</section>


<section data-background="none" data-background-transition="none" data-transition="none">
	<h3>Finding branch lengths</h3>
   <br>
			<p>
				Branch lengths $b$ can computed numerically by maximizing the log-likelihood of the whole alignment $X$,
				which is a sum of the log-likelihoods at the particular sites:
        $l(b | X,\tau)=\underset{j=1}{\overset{l}{\sum}}log\left(L(b | \mathbf{x}_{j},\tau)\right)$
			</p>
<br>
<br>
				<p class="fragment">
					This means finding those branch lengths for tree $\tau$ which maximize the log-likelihood function.
			  </p>
</section>


<section data-background="none" data-background-transition="none" data-transition="none">
	<h3>Finding model parameters</h3>
   <br>
	 <ul>
 		<li>Model parameters $\Theta$ can be estimated similarly to estimating branch lengths.</li>
 		<li>Using the observed alignment and a fixed tree find the parameters which maximize the log-likelihood:
<br>
$l(\Theta|X,\tau,b)$
		</li>
 	</ul>

</section>




<section data-background="none" data-background-transition="none" data-transition="none">
	<h3>Searching through tree space</h3>
	<div class="row">
		<div class="col-sm-6">
<a class="stretch"><img src="images/table1.png"></a>
		</div>
		<div class="col-sm-6">

			<p>
				Finding the tree that maximizes the likelihood of observing tip sequence requires a search through the space of all possible tree topologies and branch lengths.
			</p>

				<!-- <p class="fragment">
Impossible, but in the smallest cases
			</p> -->

		</div>
	</div>
</section>


<!-- summarize heuristic algs p 190 from the the book -->
<section data-background="images/overImg.png" data-background-transition="none" data-transition="none">
	<h3>Searching through tree space</h3>
   <br>
			<p>
				<!-- Branch lengths can be computed numerically by maximizing the log-likelihood for a single tree. -->
				The big task that remains is to actually find the tree among all possible tree topologies that maximizes the global likelihood.
			</p>

			<p class="fragment">
				No efficient algorithms exist that guarantee to find the ML tree, even for moderately sized data sets.
		 </p>

		<p class="fragment">
		   Most programs resort to various heuristic approaches to suggest reasonable trees.
    </p>

</section>


<section data-background="#cce8cf" data-background-transition="none" data-transition="none">
	<h3>Heuristic searches of the tree space</h3>
</section>


<section data-background="none" data-background-transition="none" data-transition="none">
	<h3>Stepwise addition search</h3>
	<div class="row">
		<div class="col-sm-6">
<a class="stretch"><img src="images/stepwise_addition.png"></a>
		</div>
		<div class="col-sm-6">
<font size=6>
<!-- procedure starts from -->
			<p>
				Start from unrooted tree of 3 taxa, randomly selected from $n$, reconstruct corresponding ML sub-tree.
			</p>

			<p class="fragment">
				Randomly pick one of the remaining $n-3$ taxa, insert into each branch of the ML sub-tree.
		 </p>

		 <p class="fragment">
			 From the list of $2k-n$ trees, where $k$ is the number of added taxa, select the one which maximizes the likelihood.
		</p>
</font>
		</div>
	</div>
</section>


<section data-background="images/overImg.png" data-background-transition="none" data-transition="none">
	<h3>Stepwise addition search</h3>
	<div class="row">
		<div class="col-sm-6">
<a class="stretch"><img src="images/stepwise_addition.png"></a>
		</div>
		<div class="col-sm-6">

			<p>
				After $n-3$ steps a maximum likelihood tree is obtained, which is at least a local optima.
			</p>

			<!-- it is possible that another insertion order of the taxa will provide a tree with a higher likelihood. -->
			<p class="fragment">
				The result is highly dependent on the insertion order.
		 </p>

		 <p class="fragment">
			To reduce the risk of getting stuck in local maximum tree-rearrangement operations acting on the full tree were suggested.
		</p>

		</div>
	</div>
</section>


<!-- style="width: 100%; height: 100%;" -->

<!-- see p283 the book -->
<section data-background="images/overImg.png" data-background-transition="none" data-transition="none">
	<h3>Full tree rearrangement </h3>
<a class="stretch"><img src="images/rearrangement.png"></a>
			<p>
				Generate a number of trees from a starting tree (the neighborhood of the starting tree) using three operations:
			</p>
</section>


<section data-background="images/overImg.png" data-background-transition="none" data-transition="none">
	<h3>Full tree rearrangement </h3>
<a class="stretch"><img src="images/rearrangement.png"></a>
			<p>
		<font color="#df8f09">	Nearest neighbor interchange (NNI):</font>
			Visits each branch, swapping a subtree connected to one end of the branch with a subtree connected to
			the other end of the branch, resulting in two different topologies, compares the likelihood to the original tree.
			</p>
</section>


<section data-background="images/overImg.png" data-background-transition="none" data-transition="none">
	<h3>Full tree rearrangement </h3>
<a class="stretch"><img src="images/rearrangement.png"></a>
			<p>
				<font color="#df8f09">	Subtree pruning and regrafting (SPR):</font>
				Involves clipping off all possible subtrees
			 from the main tree and reinserting them at all possible locations, avoiding repetitions.
			</p>
</section>


<section data-background="images/overImg.png" data-background-transition="none" data-transition="none">
	<h3>Full tree rearrangement </h3>
<a class="stretch"><img src="images/rearrangement.png"></a>
			<p>
				<font  size = 5.5 color="#df8f09">	Tree bisection and reconnection (TBR):</font>
				<font size = 5.5>Involves cutting a tree into two subtrees by cutting one branch, and reconnecting the two
subtrees by creating a new branch that joins a branch on one subtree to a branch
on the other sub-tree.
 All possible branches are tried, avoiding repetitions.
 </font>
			</p>
</section>


<section data-background="#cce8cf" data-background-transition="none" data-transition="none">
	<h3>Assessing evolutionary trees and models </h3>
</section>


<section data-background="none" data-background-transition="none" data-transition="none">
	<h3>Are two evolutionary trees/models different?</h3>
<p>
We already know how given a sequence alignment data and a substitution models to reconstruct
trees and compute their likelihoods.
</p>
<br>
<p class="fragment">
	But can we decide from the likelihood:
	<ul class="fragment">
		<li>Which substitution model better fits the data?</li>
		<li> Which reconstructed tree is better (in terms of their likelihoods)?</li>
		<li> Whether one tree likelihood is significantly better/worse?</li>
	</ul>
</p>
<br>
<p class="fragment">
	These questions can be assesed by performing hypothesis tests.
</p>
</section>


<section data-background="none" data-background-transition="none" data-transition="none">
<h3>Likelihood ratio test (LRT)</h3>
<div class="row">
	<div class="col-sm-6">
<a class="stretch"><img src="images/lrt.png"></a>
	</div>
	<div class="col-sm-6">
	<font size=5>
		<p>
			If two models are nested (like TN in GTR), their log-likelihood difference $2\left(l\left(\text{GTR}\right)-l\left(\text{TN}\right)\right)$
		follows a $\chi^{2}$ distribution with degrees of freedom equal to the number of additional
		parameters ($df = 3$).
		</p>
<br>
		<p class="fragment">
				<font>$H_{0}$</font>: both models are equally good.
				<br>
				<font>$H_{A}$</font>: the more complex model is better.
		</p>
	</font>
	</div>
</div>
</section>


<section data-background="none" data-background-transition="none" data-transition="none">
	<h3>Likelihood ratio test (LRT)</h3>
	<div class="row">
		<div class="col-sm-6">
			<a class="stretch"><img src="images/lrt.png"></a>
		</div>
		<div class="col-sm-6">
			<font size=5>
		<p>
				$H_{0}$: both models are equally good.
			<br>
			$H_{A}$: the more complex model is better.
			</p>

			<p>
				We test <b>against the $H_{0}$.</b>
			</p>

			<p>
				<a href="https://en.wikipedia.org/wiki/P-value">P-value</a>: expresses the probability of finding
				a value of the test statistic which is equal to or even more extreme then the observed test statistic:
				<br>
				$P(\left|T\right| \geq t|H_{0})$
        <br>
				Indicates how unusual (how far in the tails) the observed result for the test statistic is:
				<ul>
					<li>$>0.1$ : not significant (accept $H_{0}$) </li>
					<li>$0.05-0.10$ : $H_{A}$ is marginally significant</li>
					<li>$0.01-0.05$ : $H_{A}$ is significant </li>
					<li>$0.001-0.01$ : $H_{A}$ is strongly significant</li>
					<li> $
						< 0.001$ : $H_{A}$ is extremely significant </li>
				</ul>
			</p>

			</font>
		</div>
	</div>
</section>



<section data-background="none" data-background-transition="none" data-transition="none">
	<h3>Testing tree topologies</h3>

<!-- likelihood diff had unknown distribution -->
<p>
	Two different topologies are not nested, thus, we cannot use the $\chi^{2}$ distribution.
</p>

<p class="fragment">
	Hence, bootstrap-based methods have been applied to
determine the distribution of log-likelihood differences for testing.
</p>

</section>

<!--  bootstrap -->
<!-- bootstrap because of baron muchausen -->
<section data-background="none" data-background-transition="none" data-transition="none">
	<h3>Bootstrap - basic idea</h3>

	<ul>
		<li> Compute log-likelihood values $l_{1},\ldots,l_{N}$ for tree topologies $\tau_{1},\ldots,\tau_{N}$.</li>
		<li>
			Draw 	<font color="#df8f09">bootstrap samples</font> $i$ from the alignment,
			re-estimate the log-likelihood values $l_{X}^{\left(i\right)}$
      for each tree $T_{x}$ and for each sample $i$.
		</li>

		<li>
Center the log-likelihoods with the mean $\overline{l}_{X}^{\left(i\right)}$ by setting
$\tilde{l}_{X}^{\left(i\right)}=l_{X}^{\left(i\right)}-\overline{l}_{X}^{\left(i\right)}$.
		</li>
<li>
		Use the differences between the $\tilde{l}_{X}^{\left(i\right)}$ to determine the <font color="#df8f09">non-parametric distribution</font> of differences:
		$\delta^{\left(i\right)}=\tilde{l}_{Y}^{\left(i\right)}-\tilde{l}_{Z}^{\left(i\right)}$.
	</li>

	<li>
			Use the distribution of $\delta^{\left(i\right)}$ to test the trees.
		</li>

	</ul>

</section>


<!-- TODO: bootstrap example-->



			<section data-background="images/overImg.png" data-background-transition="none">
				<!-- very happy  to answer all questions you might have -->
				<h2>Thank you!</h2>
				<h2><font color="#df8f09"> Questions?</font></h2>
			</section>

		</div>
	</div>

	<script src="../reveal/lib/js/head.min.js"></script>
	<script src="../reveal/js/reveal.min.js"></script>
	<script src="../reveal/js/config.js"></script>

</body>

</html>
